= oc / kubectl : 쿠버네티스 클라이언트


== Kubernetes 및 OpenShift 명령줄 인터페이스
웹 콘솔에서 kubectl 또는 oc CLI(명령줄 인터페이스)를 사용하여 OpenShift 클러스터를 관리할 수 있습니다. 
두 CLI의 차이점을 아래와 같습니다.

* *kubectl*

kubernetes에서 기본적으로 제공 및 사용되는 CLI(CommandLine Interface)입니다. 
Kubernetes API와 상호작용하여 클러스터를 관리하는 데에 사용됩니다.
표준 Kubernetes 명령어를 지원하며, 모든 kubernetes 기반의 클러스터에서 동작합니다.

* *oc*

OpenShift에서 제공하는 CLI(CommandLine Interface)입니다. 
Kubernetes 관리 기능 및 추가적인 기능(예: 추가 클러스터 관리명령, OpenShift 고유 리소스 관리 등)을 제공합니다.
kubectl 명령어를 기본적으로 포함합니다.


oc 커맨드를 사용하면 터미널에서 애플리케이션을 생성하고 Red Hat OpenShift Container Platform(RHOCP) 프로젝트를 관리할 수 있습니다. 
OpenShift CLI는 다음과 같은 상황에 적합합니다.

* 프로젝트 소스 코드를 사용하여 직접 작업

* OpenShift Container Platform 작업 스크립팅

* 대역폭으로 제한된 프로젝트 관리

* 웹 콘솔을 사용할 수 없는 경우

* routes 및 deployment configs와 같은 OpenShift 리소스 작업


NOTE: 여기서부터 실습에서 사용되는 모든 명령어는 `Lab 접속방법`에서 안내되었던 CLI 터미널 창에서 수행됩니다. 

== CLI 터미널 접속

OpenShift 웹콘솔의 오른쪽 상단의 웹터미널 아이콘을 클릭하여 CLI 터미널 창을 엽니다.
그 다음 '시작'버튼을 눌러 터미널을 활성화 합니다.

image::2-1.png[2-1]

image::2-3.png[2-3]

[[talk]]
== 클러스터에 로그인하고, 설정을 확인

NOTE: 일반적으로 클러스터에서 oc(kubectl) 명령어를 사용하기 위해서는 `oc login` 명령어를 통해 클러스터에 로그인해야 합니다. +
이 실습에서는 OpenShift의 웹콘솔에서 제공하는 웹터미널을 사용하기 때문에(이미 웹콘솔 로그인이 되어 있기 때문에) 로그인 단계가 필요없습니다.

[#kubectl-view-config]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl config view
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
apiVersion: v1
clusters:
- cluster:
    certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    server: https://172.30.0.1:443
  name: https://172.30.0.1:443
contexts:
- context:
    cluster: https://172.30.0.1:443
    namespace: openshift-terminal
    user: admin
  name: admin-context
current-context: admin-context
kind: Config
preferences: {}
users:
- name: admin
  user:
    token: REDACTED
----
NOTE: 현재 kubectl 설정 파일의 내용을 출력합니다. 여기에는 클러스터, 사용자 인증 정보, 컨텍스트 등의 정보가 포함됩니다.


[#kubectl-view-config]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc config view
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
apiVersion: v1
clusters:
- cluster:
    certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    server: https://172.30.0.1:443
  name: https://172.30.0.1:443
contexts:
- context:
    cluster: https://172.30.0.1:443
    namespace: openshift-terminal
    user: admin
  name: admin-context
current-context: admin-context
kind: Config
preferences: {}
users:
- name: admin
  user:
    token: REDACTED
----

NOTE: 기본적으로 `oc` 명령어는 `kubectl` 명령을 포함하고 있기 때문에 두 명령어의 결과는 동일합니다. 또한 `oc` 명령어는 `kubectl` 에는 포함되어 있지않은 추가 리소스에 대한 명령어도 포함하고 있습니다.

IMPORTANT: 앞으로의 실습에는 `oc` 명령어를 사용합니다.




== 노드, 시스템, 시스템 구성의 개요
Kubernetes에서 노드 는 포드를 실행할 수 있는 클러스터의 단일 시스템입니다. 이러한 시스템은 클러스터의 멤버인 베어 메탈, 가상 또는 클라우드 컴퓨터 중 하나입니다. 노드는 클러스터 내에서 통신하고 컨트롤 플레인 운영 요청을 수신하는 데 필요한 서비스를 실행합니다. 포드를 배포할 때 사용 가능한 노드는 요청을 충족하는 작업을 수행합니다.

노드 및 시스템 이라는 용어는 흔히 서로 바꿔 사용할 수 있지만 Red Hat OpenShift Container Platform(RHOCP)에서는 시스템 이라는 용어를 더 구체적으로 사용합니다. OpenShift에서 시스템 은 클러스터 노드를 설명하는 리소스입니다. 

* *Master Node* : Master 노드는 클러스터의 관리 및 제어 역할을 담당합니다. 모든 클러스터 상태와 관리 작업은 Master 노드에서 이루어집니다. 다음과 같은 주요 역할을 수행합니다.
 - API Server (Kube-apiserver) : 클러스터와 상호작용하는 진입점(API 엔드포인트)을 제공하고, 사용자, 개발자, 클라이언트와 통신하여 요청을 처리합니다.
 -  Scheduler (Kube-scheduler) : 워크로드(Pod)를 적절한 Worker 노드에 배치합니다. 리소스 상태와 요구 사항을 기반으로 최적의 노드를 선택합니다.
 -  Controller Manager (Kube-controller-manager) : 클러스터 상태를 원하는 상태로 유지합니다.
 -  Etcd : 클러스터의 모든 상태 정보를 저장하는 분산형 키-값 저장소.

* *Worker Node* : Worker 노드는 실제로 워크로드(Pod, 컨테이너)를 실행하는 노드입니다. 주요 구성요소는 다음과 같습니다.
 - Kubelet : 노드 내에서 Pod를 관리하는 에이전트.
 - Kube-proxy : 네트워크 통신을 관리하는 네트워크 프록시.
 - Container Runtime : 컨테이너 실행 환경을 제공

* *Infra Node* : Infra 노드는 클러스터 서비스(내부 서비스)를 실행하는 전용 노드로, 사용자 워크로드와 분리된 환경에서 동작하도록 설계되었습니다.
 - 클러스터 서비스 호스팅 : 클러스터 내 네트워크, 모니터링, 로깅, 레지스트리 등 OpenShift 내부 서비스 실행.
 - 로드 밸런싱 및 네트워크 게이트웨이 : 외부 트래픽을 클러스터 내부로 라우팅.
 - 서비스 안정성 향상 : 사용자 워크로드와 클러스터 서비스를 분리하여 상호 간의 간섭을 최소화



[[view-nodes]]
== 클러스터를 구성하는 Nodes 확인

[#kubectl-get-nodes]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get nodes
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                                        STATUS   ROLES                  AGE    VERSION
ip-10-0-27-23.us-east-2.compute.internal    Ready    worker                 2d1h   v1.28.14+502c5ce
ip-10-0-29-131.us-east-2.compute.internal   Ready    worker                 2d1h   v1.28.14+502c5ce
ip-10-0-35-173.us-east-2.compute.internal   Ready    infra,worker           2d     v1.28.14+502c5ce
ip-10-0-38-201.us-east-2.compute.internal   Ready    control-plane,master   2d1h   v1.28.14+502c5ce
ip-10-0-38-226.us-east-2.compute.internal   Ready    control-plane,master   2d1h   v1.28.14+502c5ce
ip-10-0-56-21.us-east-2.compute.internal    Ready    control-plane,master   2d1h   v1.28.14+502c5ce
ip-10-0-63-222.us-east-2.compute.internal   Ready    worker                 2d1h   v1.28.14+502c5ce
----

[#kubectl-get-nodes]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get nodes --show-labels
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                                        STATUS   ROLES                  AGE    VERSION            LABELS
ip-10-0-27-23.us-east-2.compute.internal    Ready    worker                 2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m6a.8xlarge,beta.kubernetes.io/os=linux,cluster.ocs.openshift.io/openshift-storage=,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-27-23.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/worker=,node.kubernetes.io/instance-type=m6a.8xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a,topology.rook.io/rack=rack0
ip-10-0-29-131.us-east-2.compute.internal   Ready    worker                 2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m6a.8xlarge,beta.kubernetes.io/os=linux,cluster.ocs.openshift.io/openshift-storage=,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-29-131.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/worker=,node.kubernetes.io/instance-type=m6a.8xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a,topology.rook.io/rack=rack1
ip-10-0-35-173.us-east-2.compute.internal   Ready    infra,worker           2d     v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5a.2xlarge,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-35-173.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/infra=,node-role.kubernetes.io/worker=,node.kubernetes.io/instance-type=m5a.2xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a
ip-10-0-38-201.us-east-2.compute.internal   Ready    control-plane,master   2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5a.2xlarge,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-38-201.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=,node.kubernetes.io/instance-type=m5a.2xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a
ip-10-0-38-226.us-east-2.compute.internal   Ready    control-plane,master   2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5a.2xlarge,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-38-226.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=,node.kubernetes.io/instance-type=m5a.2xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a
ip-10-0-56-21.us-east-2.compute.internal    Ready    control-plane,master   2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5a.2xlarge,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-56-21.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=,node.kubernetes.io/instance-type=m5a.2xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a
ip-10-0-63-222.us-east-2.compute.internal   Ready    worker                 2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m6a.8xlarge,beta.kubernetes.io/os=linux,cluster.ocs.openshift.io/openshift-storage=,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-63-222.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/worker=,node.kubernetes.io/instance-type=m6a.8xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a,topology.rook.io/rack=rack2[[view-pods]]
----

NOTE: `oc get nodes` : 클러스터 내의 모든 노드를 목록으로 출력합니다. +
`oc get nodes --show-labels` : 노드의 정보를 출력하면서 각 노드에 적용된 라벨도 표시합니다.


== Red Hat OpenShift 주요 개념
OpenShift 기능을 탐색할 때 OpenShift, Kubernetes, 컨테이너 기술에 대한 몇 가지 입문 용어를 알고 있으면 유용합니다. +
다음 목록에는 OpenShift를 탐색하는 데 도움이 되는 몇 가지 기본 개념이 포함되어 있습니다.

* *Pod* : Kubernetes에서 관리하는 컨테이너화된 애플리케이션의 가장 작은 단위입니다. 포드는 하나 이상의 컨테이너로 구성됩니다.

* *Deployment* : 실행 중인 애플리케이션을 세부적으로 관리할 수 있는 운영 단위입니다.

* *Project* : 애플리케이션에 멀티 테넌시 범위를 제공하는 추가 주석이 있는 Kubernetes 네임스페이스입니다.

* *Routes* : 클러스터 외부 리소스에 애플리케이션 및 서비스를 노출하는 네트워킹 구성입니다.OpenShift 라우터에서 애플리케이션 및 마이크로서비스의 진입 지점으로 인식하는 DNS 호스트 이름을 나타냅니다.

* *Operators* : 클러스터 기능을 확장하며 패키지로 제공되는 Kubernetes 애플리케이션입니다.

* *Service* : 포드의 풀에 대한 액세스를 제공하는 단일 IP/포트 결합을 정의합니다. 기본적으로 서비스는 라운드 로빈 방식으로 클라이언트를 포드에 연결합니다.

* *ReplicaSet(rs)* : 지정된 수의 포드 복제본이 지정된 시간에 실행되고 있는지 확인합니다.

* *Persistent Volumes (pv)* : Kubernetes 포드에서 사용할 스토리지 영역을 정의합니다.

* *Persistent Volume Claims (pvc)* : 포드의 스토리지 요청을 나타냅니다. PVC는 일반적으로 스토리지를 컨테이너의 파일 시스템에 마운트하여 해당 컨테이너에서 프로비저닝된 스토리지를 사용할 수 있도록 PV를 포드에 연결합니다.

* *ConfigMaps(cm) 및 Secrets* : 다른 리소스에서 사용할 수 있는 일련의 키와 값이 포함되어 있습니다. ConfigMaps 및 Secrets는 여러 리소스에서 사용하는 구성 값을 중앙 집중화합니다. Secrets는 Secrets의 값이 항상 인코딩되고(암호화되지 않음) 액세스 권한이 소수의 권한 있는 사용자로 제한된다는 점에서 ConfigMaps와 다릅니다.

* *Deployment (deploy)* : 포드에 포함된 컨테이너 집합 및 사용할 배포 전략을 나타냅니다. deployment 오브젝트에는 기본 이미지, 태그, 스토리지 정의, 컨테이너가 시작될 때 실행할 명령 등 각 포드 복제본의 모든 컨테이너에 적용할 구성이 포함됩니다. Kubernetes 복제본은 OpenShift에서 독립 실행형으로 생성할 수 있지만 일반적으로 배포 컨트롤러와 같은 고급 수준의 리소스에서 생성합니다.


== 클러스터에 배포되어 있는 `Pods` 를 확인


[#kubectl-get-pods]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get pods -n codeserver-%userid%
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                          READY   STATUS    RESTARTS   AGE
codeserver-85f5475758-pxhvp   1/1     Running   0          3d7h
----


[#kubectl-get-pods]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get pods -n codeserver-%userid% --show-labels
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                          READY   STATUS    RESTARTS   AGE    LABELS
codeserver-85f5475758-pxhvp   1/1     Running   0          3d7h   app.kubernetes.io/instance=codeserver-user1,app.kubernetes.io/name=codeserver,pod-template-hash=85f5475758
----

[#kubectl-get-pods]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get pods -n codeserver-%userid% -o wide
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                          READY   STATUS    RESTARTS   AGE    IP             NODE                                        NOMINATED NODE   READINESS GATES
codeserver-85f5475758-pxhvp   1/1     Running   0          3d7h   10.128.2.116   ip-10-0-106-38.us-east-2.compute.internal   <none>           <none>
----


NOTE: `oc get pods -n codeserver-%userid%` : 해당 네임스페이스에서 실행 중인 pod의 정보를 출력합니다. +
`oc get pods -n codeserver-%userid% --show-labels` : 해당 네임스페이스에서 파드 정보를 출력하며, 파드에 적용된 라벨도 함께 표시합니다. +
`oc get pods -n codeserver-%userid% -o wide` : 파드의 정보를 좀 더 상세하게 출력합니다. 예를 들어, 노드의 이름과 IP 주소 등 추가 정보를 보여줍니다.



[[deploy-app]]
== 배포를 진행해 보세요.

네임스페이스를 생성하고  deployment를 배포합니다:

[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc new-project mystuff-%userid%
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
namespace/mystuff-%userid% created
----

NOTE: `oc new-project mystuff-%userid%` : mystuff-%userid%라는 새 프로젝트(네임스페이스)를 생성합니다.

[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc project mystuff-%userid%
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Now using project "mystuff-%userid%" on server "https://172.30.0.1:443".
----

NOTE: `oc project mystuff-%userid%` : 현재 활성화된 컨텍스트의 기본 네임스페이스를 mystuff-%userid%로 변경합니다.

[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc create deployment myapp --image=quay.io/rhdevelopers/quarkus-demo:v1
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
deployment.apps/myapp created
----


NOTE: `oc create deployment myapp --image=quay.io/rhdevelopers/quarkus-demo:v1` : quay.io/rhdevelopers/quarkus-demo:v1 이미지를 기반으로 하는 myapp이라는 이름의 `deployment` 를 생성합니다.



[[monitor-events]]
== 배포를 진행하는 동안 이벤트를 모니터링

[#kubectl-get-events]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
watch oc get events --sort-by=.metadata.creationTimestamp
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
LAST SEEN   TYPE     REASON              OBJECT                        MESSAGE
<unknown>   Normal   Scheduled           pod/myapp-5dcbf46dfc-ghrk4    Successfully assigned mystuff/myapp-5dcbf46dfc-ghrk4 to g
cp-5xldg-w-a-5ptpn.us-central1-a.c.ocp42project.internal
29s         Normal   SuccessfulCreate    replicaset/myapp-5dcbf46dfc   Created pod: myapp-5dcbf46dfc-ghrk4
29s         Normal   ScalingReplicaSet   deployment/myapp              Scaled up replica set myapp-5dcbf46dfc to 1
21s         Normal   Pulling             pod/myapp-5dcbf46dfc-ghrk4    Pulling image "quay.io/burrsutter/quarkus-demo:1.0.0"
15s         Normal   Pulled              pod/myapp-5dcbf46dfc-ghrk4    Successfully pulled image "quay.io/burrsutter/quarkus-dem
o:1.0.0"
15s         Normal   Created             pod/myapp-5dcbf46dfc-ghrk4    Created container quarkus-demo
15s         Normal   Started             pod/myapp-5dcbf46dfc-ghrk4    Started container quarkus-demo
----

NOTE: `watch oc get events` : 클러스터 이벤트를 생성 시간순으로 실시간 모니터링합니다. watch 명령은 주기적으로 결과를 갱신합니다.

NOTE: `watch` 명령어를 종료하려면, [ctrl+c]를 입력합니다.

[[created-objects]]
== 생성된 Objects를 확인하세요.

=== Deployments
[#kubectl-get-deployments]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get deployments
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
myapp   1/1     1            1           95s
----

NOTE: `oc get deployments` : 배포된 `deployments` 목록을 확인합니다.



=== Replicasets
[#kubectl-get-replicasets]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get replicasets
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME               DESIRED   CURRENT   READY   AGE
myapp-5dcbf46dfc   1         1         1       2m1s
----

NOTE: `oc get replicasets` : 배포된 `replicasets` 목록을 확인합니다.



=== Pods

[#kubectl-get-podsx]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get pods --show-labels
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                     READY   STATUS    RESTARTS   AGE     LABELS
myapp-5dcbf46dfc-ghrk4   1/1     Running   0          2m18s   app=myapp,pod-template-hash=5dcbf46dfc
----

NOTE: `oc get pods --show-labels` : 배포된 `pod` 목록을 label값을 포함하여 확인합니다.


=== Logs
[#kubectl-logs]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc logs -l app=myapp
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
2020-03-22 14:41:30,497 INFO  [io.quarkus] (main) Quarkus 0.22.0 started in 0.021s. Listening on: http://0.0.0.0:8080
2020-03-22 14:41:30,497 INFO  [io.quarkus] (main) Installed features: [cdi, resteasy]
----

NOTE: `oc logs -l app=myapp` : `app=myapp` label이 포함된 pod의 로그를 출력합니다.


== Service 노출

[#kubectl-expose]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc expose deployment myapp --port=8080 --type=LoadBalancer
----

수행하는 동안 서비스를 조회하세요.

[#{section-k8s}-kubectl-watch-services]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
watch oc get services
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME    TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
myapp   LoadBalancer   172.30.103.41   <pending>     8080:31974/TCP   4s
----

외부 IP가 할당될 때까지 기다리세요.



[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME    TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE
myapp   LoadBalancer   172.30.103.41   34.71.122.153   8080:31974/TCP   44s
----

NOTE: `watch` 명령어를 종료하려면, [ctrl+c]를 입력합니다.


== Talk to the App

OpenShift와 같은 호스팅된 Kubernetes 클러스터를 사용하는 경우 `8080` 포트와 함께 `curl` 및 EXTERNAL-IP 주소를 사용하거나 `kubectl(oc)` 을 사용하여 가져옵니다.:

IMPORTANT: AWS에 있는 경우 `ip` 대신 `hostname` 을 가져와야 합니다. 아래 명령어는 hostname을 가져옵니다.


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
IP=$(kubectl get service myapp -o jsonpath="{.status.loadBalancer.ingress[0].hostname}")
----


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
PORT=$(kubectl get service myapp -o jsonpath="{.spec.ports[*].port}")
----


Curl the Service:

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
curl $IP:$PORT
----


[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Supersonic Subatomic Java with Quarkus myapp-b484fbf6-25kcz:1
----

IMPORTANT: curl 명령어를 수행하여 app이 hosting하고 있는 문구를 확인합니다.


== Application 확장

명령줄 터미널에서 +버튼을 눌러 3개의 터미널 창을 엽니다.

image::2-4.png[2-4]



* *Terminal 1번*


[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc project mystuff-%userid%
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Now using project "mystuff-%userid%" on server "https://172.30.0.1:443".
----

[#watch-pods]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
watch oc get pods
----

NOTE: 터미널 1번은 지속적으로 pod list를 출력하며, replicaset이 변경됨에 따라 pod수가 1개에서 3개로 늘어나는 것을 확인할 수 있습니다.

* *Terminal 2번*


[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc project mystuff-%userid%
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Now using project "mystuff-%userid%" on server "https://172.30.0.1:443".
----

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
IP=$(kubectl get service myapp -o jsonpath="{.status.loadBalancer.ingress[0].hostname}")
----


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
PORT=$(kubectl get service myapp -o jsonpath="{.spec.ports[*].port}")
----


Curl the Service:

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
curl $IP:$PORT
----


Poll the endpoint:

[#poll-endpoint]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
while true
do curl $IP:$PORT
sleep 0.8
done
----

polling 결과는 다음과 같습니다.:

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:289
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:290
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:291
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:292
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:293
----

NOTE: 터미널 2번은 지속적으로 3개의 pod로의 curl poling을 시도합니다. application의 이미지를 변경하여 Rolling update가 진행됨에 따라 실시간으로 poling 결과값이 변하는 것을 관찰할 수 있습니다.


* *Terminal 3번*

[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc project mystuff-%userid%
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Now using project "mystuff-%userid%" on server "https://172.30.0.1:443".
----


replicas 변경:

[#change-replicas]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc scale deployment myapp --replicas=3
----



[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                     READY   STATUS              RESTARTS   AGE
myapp-5dcbf46dfc-6sn2s   0/1     ContainerCreating   0          4s
myapp-5dcbf46dfc-ghrk4   1/1     Running             0          5m32s
myapp-5dcbf46dfc-z6hqw   0/1     ContainerCreating   0          4s
----

NOTE: 해당 결과는 터미널 1번에서 확인합니다.  터미널 1번은 지속적으로 pod list를 출력하며, replicaset이 변경됨에 따라 pod수가 1개에서 3개로 늘어나는 것을 확인할 수 있습니다.


이미지를 변경하여 롤링 업데이트 시작:

[#set-image-myboot-v1]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc set image deployment/myapp quarkus-demo=quay.io/rhdevelopers/myboot:v1
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-6sn2s:188
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-z6hqw:169
Aloha from Spring Boot! 0 on myapp-58b97dbd95-vxd87
Aloha from Spring Boot! 1 on myapp-58b97dbd95-vxd87
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-6sn2s:189
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-z6hqw:170
Aloha from Spring Boot! 2 on myapp-58b97dbd95-vxd87
----

NOTE: 해당 결과는 터미널 2번에서 확인합니다. 터미널 2번은 지속적으로 3개의 pod로의 curl poling을 시도합니다. application의 이미지를 변경하여 Rolling update가 진행됨에 따라 실시간으로 poling 결과값이 변하는 것을 관찰할 수 있습니다.



[#set-image-myboot-v2]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc set image deployment/myapp quarkus-demo=quay.io/rhdevelopers/myboot:v2
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Bonjour from Spring Boot! 2 on myapp-7d58855c6b-6c8gd
Bonjour from Spring Boot! 3 on myapp-7d58855c6b-6c8gd
Aloha from Spring Boot! 7 on myapp-58b97dbd95-mjlwx
Bonjour from Spring Boot! 4 on myapp-7d58855c6b-6c8gd
Aloha from Spring Boot! 8 on myapp-58b97dbd95-mjlwx
Bonjour from Spring Boot! 5 on myapp-7d58855c6b-6c8gd
----

NOTE: 해당 결과는 터미널 2번에서 확인합니다. 터미널 2번은 지속적으로 3개의 pod로의 curl poling을 시도합니다. application의 이미지를 변경하여 Rolling update가 진행됨에 따라 실시간으로 poling 결과값이 변하는 것을 관찰할 수 있습니다.


[#set-image-quarkus-demo]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc set image deployment/myapp quarkus-demo=quay.io/rhdevelopers/quarkus-demo:v1
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Bonjour from Spring Boot! 14 on myapp-7d58855c6b-dw67s
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:3
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:4
Bonjour from Spring Boot! 15 on myapp-7d58855c6b-dw67s
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:5
Bonjour from Spring Boot! 13 on myapp-7d58855c6b-72wp8
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7rkxj:1
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7rkxj:2
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7lf9t:1
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7rkxj:3
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7lf9t:2
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7lf9t:3
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:6
----

NOTE: 해당 결과는 터미널 2번에서 확인합니다. 터미널 2번은 지속적으로 3개의 pod로의 curl poling을 시도합니다. application의 이미지를 변경하여 Rolling update가 진행됨에 따라 실시간으로 poling 결과값이 변하는 것을 관찰할 수 있습니다.

== Clean Up

[#delete-namespace]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc delete all --all -n mystuff-%userid%
----

NOTE: *mystuff-%userid%* namespace의 모든 리소스가 삭제됩니다.

[#delete-namespace]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc delete namespace mystuff-%userid%
----

NOTE: *mystuff-%userid%* namespace를 삭제합니다.
