= 노드 선택기, taint
전용 노드에서 실행되도록 워크로드를 구성하고 다른 워크로드가 해당 노드에서 실행되지 못하도록 합니다.

== 노드의 워크로드 보장 및 방지
OpenShift 고급 예약 기능에는 포드가 특정 노드에 배치되도록 하는 노드 선택기와 특정 노드에서 일부 워크로드를 실행하지 못하게 하는 taint 및 toleration이 포함됩니다.

노드 선택기를 사용하여 전용 노드 집합에 포드를 예약합니다. 예를 들어 포드에 필요한 특수 하드웨어를 제공하는 노드에 포드를 예약할 수 있습니다.

taint 및 toleration을 사용하여 전용 노드 집합에 포드를 예약하지 않도록 합니다. 예를 들어 OpenShift 클러스터 서비스 또는 컨트롤 플레인 서비스용으로 예약된 노드에서 실행되지 않도록 포드를 차단합니다.

== 노드 선택기
노드 선택기를 사용하면 포드에서 대상 노드 레이블을 지정할 수 있으므로 OpenShift 스케줄러는 대상 레이블과 일치하는 노드에만 포드를 배치하려고 합니다. OpenShift 스케줄러에서 대상 레이블과 일치하는 노드를 찾지 못하면 포드를 사용할 수 없습니다.

포드 노드 선택기를 사용하여 전용 노드에 포드를 배치할 수 있습니다. 포드 노드 선택기를 포드 템플릿의 속성으로 정의합니다.

프로젝트 노드 선택기를 사용하여 전용 노드에 프로젝트의 포드를 배치할 수 있습니다. 프로젝트 노드 선택기를 프로젝트 CR에서 주석으로 정의합니다.

클러스터 전체 노드 선택기를 사용하여 클러스터의 임의 위치에서 전용 노드에 포드를 배치합니다. 클러스터 전체 노드 선택기를 OpenShift 스케줄러 CR의 속성으로 정의합니다.

image::2-7.png[2-7]

이전 다이어그램은 포드 노드 선택기의 작동 방식을 보여줍니다. 그림에서 worker01 노드에는 key1=value1 레이블이 있지만 worker02 노드에는 해당 레이블이 없습니다. 첫 번째 포드의 경우 OpenShift는 노드 선택기가 없으므로 두 노드 중 하나에서 포드를 예약할 수 있습니다.

두 번째 포드에는 포드 템플릿에서 속성으로 정의된 노드 선택기가 있습니다. 그러면 OpenShift는 노드 선택기와 일치하는 레이블이 있는 노드에서만 포드를 예약할 수 있습니다. 따라서 OpenShift 스케줄러는 worker01 노드에만 포드를 배치할 수 있습니다.

* *노드 레이블*
OpenShift 스케줄러가 대상 레이블과 일치하는 노드를 찾도록 하려면 먼저 노드에 레이블을 지정합니다. 레이블을 노드 리소스에 직접 추가하거나 시스템 집합 리소스를 사용하여 간접적으로 추가할 수 있습니다.

클러스터가 시스템 집합 리소스를 지원하는 방식으로 설치된 경우 시스템 집합을 사용하여 노드에 레이블을 설정해야 합니다. 이 경우 노드에 직접 레이블을 지정하지 마십시오. 클러스터가 사용자 프로비저닝된 인프라 방법을 사용하여 설치된 경우와 같이 시스템 집합 리소스를 지원하지 않는 경우 노드에 직접 레이블을 지정해야 합니다.

TIP: 
클러스터에서 시스템 집합 리소스를 지원하는 경우 OpenShift는 언제든지 노드를 삭제하고 다시 생성할 수 있습니다. 따라서 노드에 직접 레이블을 지정하면 OpenShift에서 다시 생성할 때 시스템 집합 외부에서 노드의 레이블이 손실됩니다.

다음 명령을 사용하여 노드에 하나 이상의 레이블을 추가할 수 있습니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
[user@host ~]$ oc label node node1 key1=value1 ... keyN=valueN
node/node1 labeled
----

다음 명령을 사용하여 노드에서 레이블을 삭제할 수 있습니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
[user@host ~]$ oc label node node1 key1- ... keyN-
node/node1 unlabeled
----

* *포드 노드 선택기* 
포드에서 노드 선택기를 사용하여 OpenShift 스케줄러에서 포드를 배치하려는 대상 노드 레이블을 지정합니다.

다음 구문을 사용하여 포드에 하나 이상의 노드 선택기를 추가할 수 있습니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
  ...output omitted...
spec:
  nodeSelector:
    key1: value1
    key2: value2
...output omitted...
----

이전 예제에서 OpenShift 스케줄러는 key1=value1 및 key2=value2 레이블이 모두 있는 노드에만 포드를 배치합니다.

다음과 같이 Node-Selectors 매개 변수를 검토하여 포드의 노드 선택기를 읽을 수 있습니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
[user@host ~]$ oc describe pod myapp-95664666d-5l22c
...output omitted...
Node-Selectors:     key1:value1
                    key2:value2
...output omitted...
----

* *클러스터 전체 노드 선택기*
기본적으로 OpenShift 스케줄러는 클러스터에서 사용 가능한 모든 노드에 포드를 배치하려고 합니다. 그러나 클러스터에 생성된 새 포드에 기본 노드 선택기를 포함하도록 OpenShift 스케줄러 기본 동작을 수정할 수 있습니다. 클러스터 전체 노드 선택기를 사용하여 OpenShift에서 포드에 추가하는 기본 노드 선택기를 지정합니다. 클러스터 전체 노드 선택기를 지정하려면 관리 권한이 필요합니다.

클러스터 전체 노드 선택기를 정의하려면 다음과 같이 OpenShift 스케줄러 CR을 편집할 수 있습니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
[user@host ~]$ oc edit scheduler cluster
----

그런 다음 defaultNodeSelector 매개 변수를 지정합니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
apiVersion: config.openshift.io/v1
kind: Scheduler
metadata:
  name: cluster
...output omitted...
spec:
  defaultNodeSelector: key1=value1,key2=value2
...output omitted...
----

OpenShift 스케줄러 CR을 편집한 후 openshift-kube-apiserver 프로젝트의 포드가 재배포될 때까지 기다립니다.

이전 예제에서 클러스터에 생성하는 모든 새 포드에는 기본적으로 key1=value1 및 key2=value2 노드 선택기가 있습니다.

* *프로젝트 노드 선택기* 
프로젝트에 대한 노드 선택기를 지정할 수 있으므로 OpenShift는 프로젝트에 생성된 새 포드에 해당 노드 선택기를 포함합니다. 프로젝트 노드 선택기를 지정하려면 관리 권한이 필요합니다.

프로젝트 노드 선택기를 정의하려면 OpenShift 프로젝트 CR에 대한 YAML 파일을 생성하고 다음과 같이 metadata.annotations 섹션에서 노드 선택기를 정의할 수 있습니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
apiVersion: v1
kind: Namespace
metadata:
  name: myproject
  annotations:
    openshift.io/node-selector: key3=value3,key4=value4
...output omitted...
----

이전 예제에서 프로젝트에 생성하는 모든 새 포드에는 기본적으로 key3=value3 및 key4=value4 노드 선택기가 있습니다.

* *노드 선택기 수준*
포드, 프로젝트 및 클러스터 전체 수준에서 노드 선택기를 정의할 수 있습니다.

프로젝트 노드 선택기는 클러스터 전체 노드 선택기보다 우선합니다. 따라서 프로젝트 및 클러스터 전체 노드 선택기를 모두 정의하는 경우 OpenShift는 프로젝트 노드 선택기만 새 포드에 적용하고 클러스터 전체 노드 선택기는 적용하지 않습니다.

포드 노드 선택기는 클러스터 전체 및 프로젝트 노드 선택기에 추가됩니다. 따라서 포드 및 프로젝트 노드 선택기를 모두 정의하는 경우 OpenShift는 포드 노드 선택기와 프로젝트 노드 선택기가 모두 있는 포드를 생성합니다. 포드 및 클러스터 전체 노드 선택기를 모두 정의하는 경우 OpenShift는 포드 노드 선택기와 클러스터 전체 노드 선택기가 모두 있는 포드를 생성합니다.

IMPORTANT: 
동일한 key 문자열을 사용하지만 프로젝트 노드 선택기 또는 클러스터 전체 노드 선택기와 다른 value 문자열을 사용하여 포드 노드 선택기를 생성하면 충돌이 발생하고 OpenShift에서 포드를 생성하지 못합니다.



== taint 및 toleration
노드에서 taint를 사용하여 특정 노드에서 일부 워크로드를 실행하지 못하게 할 수 있습니다. OpenShift 스케줄러는 포드에 일치하는 toleration이 있는 경우에만 해당 노드에서 포드를 예약합니다.

image::2-8.png[2-8]

위 그림에서 worker01 노드에는 taint가 있지만 worker02 노드에는 taint가 없습니다. OpenShift 스케줄러는 worker01 노드에 첫 번째 포드를 배치할 수 없습니다. toleration이 taint와 일치하지 않으므로 노드에서 포드를 거부합니다. 따라서 OpenShift는 worker02 노드에서만 포드를 예약할 수 있습니다.

OpenShift는 toleration이 taint와 일치하므로 두 노드 모두에서 두 번째 포드를 예약할 수 있습니다.

=== 노드 taint
taint는 키, 값 및 효과로 구성됩니다.

키는 최대 253자의 임의 문자열입니다.

값은 최대 63자의 임의 문자열입니다.

효과는 다음 옵션 중 하나입니다.

* *NoSchedule*
포드가 taint와 일치하지 않으면 노드에서 포드가 예약되지 않도록 합니다. 노드의 기존 포드는 해당 노드에서 계속 실행됩니다.

* *PreferNoSchedule*
포드가 taint와 일치하지 않으면 스케줄러는 노드에서 포드를 예약하지 않으려고 시도합니다. 노드의 기존 포드는 해당 노드에서 계속 실행됩니다.

* *NoExecute*
포드가 taint와 일치하지 않으면 노드에서 포드가 예약되지 않도록 합니다. 스케줄러는 일치하는 toleration이 없는 노드의 기존 포드를 제거합니다.

`spec.taints` 매개 변수를 설정하거나 다음 명령을 사용하여 노드 사양 YAML 파일의 노드에 taint를 적용할 수 있습니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
[user@host ~]$ oc adm taint nodes node1 key1=value1:NoSchedule
node/node1 tainted
----

노드에 taint를 적용한 후 다음 명령을 사용하여 taint를 확인할 수 있습니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
[user@host ~]$ oc describe nodes node1
Name:               worker01
Roles:              worker
...output omitted...
Taints:             key1=value1:NoSchedule
...output omitted...
----

노드에서 taint를 제거하려면 다음 명령을 사용합니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
[user@host ~]$ oc adm taint nodes node01 key1=value1:NoSchedule-
node/node01 untainted
----


=== 포드 toleration

toleration은 노드 taint와 유사하게 키, 값 및 효과로 구성됩니다. toleration에는 operator 매개 변수도 포함됩니다. operator 매개 변수에 사용할 수 있는 값은 다음과 같습니다.

* *Equal*
키, 값, 효과 매개 변수가 일치하는 경우 toleration이 taint와 일치합니다. 이는 기본 동작입니다.

* *Exists*
키 및 값 매개 변수가 일치하는 경우 toleration이 taint와 일치합니다. 값 매개 변수를 비워 두어야 합니다.

NoExecute 효과를 사용하여 toleration을 정의하는 경우 tolerationSeconds 매개 변수도 정의할 수 있습니다. tolerationSeconds 매개 변수는 노드에서 포드를 제거하기 전에 포드가 노드 내에 유지되는 시간을 정의합니다.

다음과 같이 spec.tolerations 매개 변수를 설정하여 포드 사양 YAML 파일의 포드에 toleration을 적용할 수 있습니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
  ...output omitted...
spec:
  tolerations:
  - key: "key1"
    operator: "Equal"
    value: "value1"
    effect: "NoExecute"
    tolerationSeconds: 3600
...output omitted...
---- 

OpenShift는 key1=value1:NoExecute taint를 사용하여 노드에서 포드를 예약할 수 있습니다. OpenShift가 taint가 있는 노드에서 포드를 예약하는 경우 노드에서 3600초 동안 포드가 실행된 후, 노드가 포드를 제거하고 OpenShift에서 포드를 다른 노드로 다시 예약합니다.

*  *포드 예약 및 노드 조건*
기본적으로 OpenShift는 조건에 따라 노드를 taint하고 제거합니다. 예를 들어 OpenShift는 메모리 또는 디스크 압력과 같은 일부 조건에서 노드를 자동으로 taint합니다.

다음 taint가 OpenShift에 빌드됩니다.

- `node.kubernetes.io/not-ready`
노드가 준비되지 않았습니다. 이 taint는 Ready=False 노드 조건에 해당합니다.

- `node.kubernetes.io/unreachable`
노드 컨트롤러에서 노드에 연결할 수 없습니다. 이 taint는 Ready=Unknown 노드 조건에 해당합니다.

- `node.kubernetes.io/memory-pressure`
노드에 메모리 압력 문제가 있습니다. 이 taint는 MemoryPressure=True 노드 조건에 해당합니다.

- `node.kubernetes.io/disk-pressure`
노드에 디스크 압력 문제가 있습니다. 이 taint는 DiskPressure=True 노드 조건에 해당합니다.

- `node.kubernetes.io/network-unavailable`
노드 네트워크를 사용할 수 없습니다.

- `node.kubernetes.io/unschedulable`
노드를 예약할 수 없습니다.

- `node.cloudprovider.kubernetes.io/uninitialized`
이 taint는 외부 클라우드 프로바이더에서 노드 컨트롤러를 시작할 때 노드를 사용할 수 없는 것으로 설정합니다. 클라우드 컨트롤러 관리자가 노드를 초기화하면 kubelet에서 taint를 제거합니다.

- `node.kubernetes.io/pid-pressure`
노드에 PID(프로세스 식별자) 압력이 있습니다. 이 taint는 PIDPressure=True 노드 조건에 해당합니다.

노드가 위 표의 조건 중 하나를 보고하면 OpenShift는 조건이 지워질 때까지 노드에 taint를 적용합니다.

예를 들어 다음 예제에 따라 OpenShift에서 예약할 수 없는 포드에 node.kubernetes.io/unschedulable taint를 자동으로 적용하는 방법을 확인할 수 있습니다. 먼저 다음 명령을 사용하여 노드의 taint를 확인합니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
[user@host ~]$ oc describe nodes node1 | grep Taints
Taints:     <none>
----

노드를 예약할 수 없음으로 표시합니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
[user@host ~]$ oc adm cordon node1
node/node1 cordoned
----

마지막으로 OpenShift에서 NoSchedule 효과가 있는 node.kubernetes.io/unschedulable taint를 노드에 자동으로 적용하는지 확인합니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
[user@host ~]$ oc describe nodes node1 | grep Taints
Taints:     node.kubernetes.io/unschedulable:NoSchedule
----

OpenShift는 NoSchedule 효과를 사용하여 이전 표의 노드에 taint를 적용합니다. 단, OpenShift에서 NoExecute 효과를 사용하는 node.kubernetes.io/not-ready 및 node.kubernetes.io/unreachable taint는 제외됩니다.

NoSchedule 효과가 있는 taint의 경우 포드에 일치하는 toleration이 있거나 노드가 정상 상태로 돌아가지만 실행 중인 포드가 변경되지 않은 상태로 남아 있는 경우 OpenShift 스케줄러는 포드를 노드에 예약합니다.

NoExecute 효과가 있는 taint의 경우 포드에 일치하는 toleration이 있거나 노드가 정상 상태로 돌아가지만 실행 중인 포드를 제거하고 다른 노드에 다시 예약하는 경우 OpenShift 스케줄러는 포드를 노드에 예약합니다. taint를 허용하지 않고 노드에서 실행 중인 포드의 경우 OpenShift에서 해당 포드를 즉시 제거합니다. toleration과 일치하는 포드의 경우 tolerationSeconds 매개 변수가 포드에 정의된 경우에만 OpenShift에서 해당 포드를 제거합니다. tolerationSeconds 매개 변수는 노드에서 포드를 제거하기 전에 포드가 노드 내에 유지되는 시간을 초 단위로 정의합니다.

tolerationSeconds 매개 변수는 애플리케이션을 처음 실행할 때 로컬 파일을 생성해야 하는 경우와 같은 특정 시나리오에서 유용합니다. 이 경우 포드가 복구될 때까지 몇 초 동안 기다리는 것이 다른 노드에서 포드를 직접 다시 생성하는 것보다 나을 수 있습니다. 애플리케이션에 대해 tolerationSeconds 매개 변수를 정의하는 경우 노드는 포드를 제거하기 전에 지정된 시간 동안 기다립니다.

== 프로젝트 toleration
프로젝트에 대한 toleration을 지정할 수 있으므로 OpenShift는 프로젝트에 생성된 새 포드에 해당 toleration을 포함합니다. 프로젝트 toleration을 지정하려면 관리 권한이 필요합니다. 프로젝트 및 포드 toleration을 정의하면 OpenShift에서 이러한 toleration을 모두 사용하여 포드를 생성합니다.

프로젝트 toleration을 정의하려면 OpenShift 프로젝트 CR에 대한 YAML 파일을 생성하고 다음과 같이 metadata.annotations 섹션에서 toleration을 정의할 수 있습니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
kind: Project
apiVersion: project.openshift.io/v1
metadata:
  name: myproject
  annotations:
    scheduler.alpha.kubernetes.io/defaultTolerations: >-
      [{"operator":"Equal","effect":"NoSchedule","key":"key1","value":"value1"}]
----

이전 예제에서 프로젝트에 생성하는 모든 새 포드에는 기본적으로 key1=value1:NoSchedule toleration이 있습니다.

=== 모든 taint 허용
키 또는 값 매개 변수 없이 operator: "Exists" toleration을 사용하여 모든 노드 taint를 허용하도록 포드를 구성할 수 있습니다.

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
...output omitted...
spec:
  tolerations:
  - operator: "Exists"
----


= Taints and Affinity

지금까지 Kubernetes 클러스터에 Pod를 배포하면 요구 사항(예: 메모리 요구 사항, CPU 요구 사항 등)을 충족하는 모든 노드에서 실행되었습니다. 그러나 Kubernetes에는 다음을 추가로 구성할 수 있는 두 가지 개념이 있습니다.  일부 비즈니스 기준에 따라 Pod가 노드에 할당되도록 스케줄러를 사용합니다.

== Preparation



[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc new-project taint-%userid%
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
namespace/taint-%userid% created
----

NOTE: `oc new-project taint-%userid%` : taint-%userid%라는 새 프로젝트(네임스페이스)를 생성합니다.

[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc project taint-%userid%
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Now using project "taint-%userid%" on server "https://172.30.0.1:443".
----

NOTE: `oc project taint-%userid%` : 현재 활성화된 컨텍스트의 기본 네임스페이스를 taint-%userid%로 변경합니다.



네임스페이스에서 아무것도 실행되고 있지 않은지 확인하세요.

[#no-resources-resource]
[.console-input]
[source, bash]
----
oc get all
----

[.console-output]
[source,bash]
----
No resources found in myspace namespace.
----


=== Watch Nodes


무슨 일이 일어나고 있는지 관찰할 수 있도록 다른 Terminal#2를 열고 다양한 작업을 실행할 때 어떤 일이 일어나는지 `관찰`해 보겠습니다.


* *Terminal#2에서 작업*


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
watch -n 1 "oc get pods -o wide \
  | awk '{print \$1 \" \" \$2 \" \" \$3 \" \" \$5 \" \" \$7}' | column -t"
----


TIP: `-o wide` 옵션을 사용하면 포드가 예약된 노드를 볼 수 있습니다. +
줄이 너무 길어지는 것을 방지하기 위해 `awk`와 `column`을 사용하여 원하는 열만 가져오고 형식을 지정합니다.



== Taints

특정 Pod를 예약하거나 예약하지 않도록 스케줄러에 신호를 보내는 Kubernetes 노드에 Taint가 적용됩니다. +
Toleration은 Pod 정의에 적용되고 Taint에 예외를 제공합니다. 현재 노드를 설명하겠습니다. +
이 경우 OpenShift 클러스터는 다음과 같습니다. 


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc describe nodes | egrep "Name:|Taints:"
----

[.console-output]
[source,bash]
----
Name:               ip-10-0-136-107.eu-central-1.compute.internal
Taints:             node-role.kubernetes.io/master:NoSchedule
Name:               ip-10-0-140-186.eu-central-1.compute.internal
Taints:             <none>
Name:               ip-10-0-141-128.eu-central-1.compute.internal
Taints:             <none>
Name:               ip-10-0-146-109.eu-central-1.compute.internal
Taints:             <none>
Name:               ip-10-0-150-226.eu-central-1.compute.internal
Taints:             <none>
----

NOTE: 이 경우 '마스터' 노드에는 애플리케이션 포드가 예약되는 것을 차단하는 오염이 포함되어 있습니다.


모든 노드에 taint를 추가해 보겠습니다.

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl taint nodes --all=true color=blue:NoSchedule
----

[.console-output]
[source,bash]
----
node/ip-10-0-136-107.eu-central-1.compute.internal tainted
node/ip-10-0-140-186.eu-central-1.compute.internal tainted
node/ip-10-0-141-128.eu-central-1.compute.internal tainted
node/ip-10-0-146-109.eu-central-1.compute.internal tainted
node/ip-10-0-150-226.eu-central-1.compute.internal tainted
node/ip-10-0-155-122.eu-central-1.compute.internal tainted
node/ip-10-0-162-206.eu-central-1.compute.internal tainted
node/ip-10-0-168-102.eu-central-1.compute.internal tainted
node/ip-10-0-175-64.eu-central-1.compute.internal tainted
----

color=blue는 단순히 오염을 식별하기 위한 키=값 쌍이고 NoSchedule은 오염을 "허용"할 수 없는 포드에 대한 특정 효과입니다.  즉, Pod가 "color=blue"를 허용하지 않으면 효과는 "NoSchedule"이 됩니다.


그럼 이것을 시험해 봅시다.  기본 터미널에서 특별한 허용 사항이 없는 새 포드를 배포합니다.



* *Terminal#1*

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
cat <<EOF | oc create -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: myboot
  name: myboot
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myboot
  template:
    metadata:
      labels:
        app: myboot
    spec:
      containers:
      - name: myboot
        image: quay.io/rhdevelopers/myboot:v1
        ports:
          - containerPort: 8080
EOF
----


Terminal#2의 출력이 변경되는 것을 볼 수 있습니다.

[.console-output]
[source,bash,subs="+quotes"]
----
NAME                      READY   STATUS    AGE     NODE
myboot-7cbfbd9b89-hqx6h   0/1     #Pending#   4m12s   devnation
----


사용 가능한 예약 가능한 노드가 없으므로 포드는 'Pending' 상태로 유지됩니다.

다음을 입력하면 이에 대한 더 많은 통찰력을 얻을 수 있습니다.



[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc describe pod #<.>
----
<.> 이 경우 포드는 하나만 있습니다.  구체적으로 지정하려면 포드 이름을 추가할 수 있습니다(예: `myboot-7f889dd6d-n5z55`))


[.console-output]
[source,bash,subs="+quotes"]
----
Name:           myboot-7f889dd6d-n5z55
Namespace:      kubetut
Priority:       0
Node:           <none>
Labels:         app=myboot
                pod-template-hash=7f889dd6d
Annotations:    openshift.io/scc: restricted
Status:         Pending

Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type     Reason            Age        From               Message
  ----     ------            ----       ----               -------
  Warning  FailedScheduling  <unknown>  default-scheduler  #0/9 nodes are available: 9 node(s) had taints that the pod didn't tolerate.#
  Warning  FailedScheduling  <unknown>  default-scheduler  #0/9 nodes are available: 9 node(s) had taints that the pod didn't tolerate.#
----


클러스터의 노드 목록을 가져오겠습니다.

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get nodes
----

[.console-output]
[source,bash]
----
NAME                                            STATUS   ROLES    AGE   VERSION
ip-10-0-136-107.eu-central-1.compute.internal   Ready    master   20h   v1.16.2
ip-10-0-140-186.eu-central-1.compute.internal   Ready    worker   20h   v1.16.2
ip-10-0-141-128.eu-central-1.compute.internal   Ready    worker   18h   v1.16.2
ip-10-0-146-109.eu-central-1.compute.internal   Ready    worker   18h   v1.16.2
ip-10-0-150-226.eu-central-1.compute.internal   Ready    worker   20h   v1.16.2
ip-10-0-155-122.eu-central-1.compute.internal   Ready    master   20h   v1.16.2
ip-10-0-162-206.eu-central-1.compute.internal   Ready    worker   20h   v1.16.2
ip-10-0-168-102.eu-central-1.compute.internal   Ready    master   20h   v1.16.2
ip-10-0-175-64.eu-central-1.compute.internal    Ready    worker   18h   v1.16.2
----

그리고 오염을 *제거*할 노드 하나를 선택합니다.

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl taint node ip-10-0-175-64.eu-central-1.compute.internal color:NoSchedule- 
----

IMPORTANT : nodename은 실제 조회된 nodenamewnd 하나를 입력합니다.

NOTE:  여기에 `-`를 추가하는 것은 문제의 오염을 제거한다는 의미입니다(`NoSchedule` 작업과 함께 `color`).


[.console-output]
[source,bash,subs="+attributes"]
----
node/{chosen-node}  untainted
----



이제 Terminal#2에서 새로 포함되지 않은 노드에 예약된 Pod가 표시됩니다.

[.console-output]
[source,bash,subs="+quotes"]
----
NAME                      READY   STATUS              AGE       NODE
myboot-7cbfbd9b89-hqx6h   0/1     #ContainerCreating#   20m   ip-10-0-175-64.eu-central-1.compute.internal
----


마지막으로 모든 노드의 taint 상태를 간단히 살펴보겠습니다.

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc describe nodes | egrep "Name:|Taints:"
----

[.console-output]
[source,bash]
----
Name:               ip-10-0-136-107.eu-central-1.compute.internal
Taints:             node-role.kubernetes.io/master:NoSchedule
Name:               ip-10-0-140-186.eu-central-1.compute.internal
Taints:             <none>
Name:               ip-10-0-141-128.eu-central-1.compute.internal
Taints:             color=blue:NoSchedule
Name:               ip-10-0-146-109.eu-central-1.compute.internal
Taints:             color=blue:NoSchedule
----


=== Restore Taint

노드(또는 이 경우 모든 노드)에 taint를 다시 추가합니다.


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl taint nodes --all=true color=blue:NoSchedule --overwrite
----

[TIP]
====
모든 노드에 taint를 설정하는 것은 약간 엉성합니다.  원한다면 제거된 노드에만 taint를 설정하여 동일한 효과를 좀 더 우아하게 얻을 수 있습니다.  예를 들어,

----
kubectl taint node ip-10-0-140-186.eu-central-1.compute.internal color=blue:NoSchedule
----
====

taint가 변경되었음에도 불구하고 Pod가 계속 실행되고 있는지 살펴보세요. (이는 Pod 수명 주기에서 일회성 활동으로 예약하기 때문입니다.)


[.console-output]
[source,bash,subs="+macros,+attributes,+quotes"]
----
NAME                      READY   STATUS    AGE   NODE
myboot-7cbfbd9b89-bzhxw   1/1     #Running#   18m   ip-10-0-175-64.eu-central-1.compute.internal
----



=== Clean Up

myboot 배포를 취소하고 노드에 taint를 다시 추가합니다.

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl delete deployment 
----



== Tolerations

오염된 노드에 예약할 수 있도록 톨러레이션이 포함된 포드를 생성해 보겠습니다.

[source, yaml]
----
spec:
  tolerations:
  - key: "color"
    operator: "Equal"
    value: "blue"
    effect: "NoSchedule"
  containers:
  - name: myboot
    image: quay.io/rhdevelopers/myboot:v1
----




[.console-input]
[source,bash,subs="+macros,+attributes"]
----
cat <<EOF | oc create -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: myboot
  name: myboot
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myboot
  template:
    metadata:
      labels:
        app: myboot
    spec:
      tolerations:
      - key: "color"
        operator: "Equal"
        value: "blue"
        effect: "NoSchedule"
      containers:
      - name: myboot
        image: quay.io/rhdevelopers/myboot:v1
        ports:
          - containerPort: 8080
EOF
----


그런 다음 얼마 지나지 않아 감시 창에서 포드가 예약되고 실행 상태로 진행되는 것을 확인해야 합니다.



[.console-output]
[source,bash,subs="+quotes"]
----
NAME                      READY   STATUS    AGE     NODE
myboot-84b457458b-mbf9r   1/1     #Running#   3m18s   devnation-m02
----


이제 모든 노드에 오염이 포함되어 있더라도 color=blue 오염에 대한 허용 오차를 정의한 대로 Pod가 예약되고 실행됩니다.

=== Clean Up

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc delete deployment myboot
----



== `NoExecution` Taint

지금까지 'NoSchedule' 오염 효과를 살펴보았습니다. 이는 새로 생성된 포드가 우선적인 허용 범위를 갖지 않는 한 그곳에서 예약되지 않는다는 것을 의미합니다. 그러나 이미 실행 중이거나 예약된 포드가 있는 노드에 이 오염을 추가하면,  이 오염은 그들을 제거하지 못할 것입니다.


NoExecution 효과를 사용하여 이를 변경해 보겠습니다.  우선 이전 taint를 모두 제거해 보겠습니다.


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl taint nodes --all=true color=blue:NoSchedule-
----



그런 다음 myboot의 다른 인스턴스를 배포합니다.(with no Tolerations):


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
cat <<EOF | oc create -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: myboot
  name: myboot
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myboot
  template:
    metadata:
      labels:
        app: myboot
    spec:
      containers:
      - name: myboot
        image: quay.io/rhdevelopers/myboot:v1
        ports:
          - containerPort: 8080
EOF
----



Terminal#2에서 다음을 확인합니다.

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
watch -n 1 "oc get pods -o wide \
  | awk '{print \$1 \" \" \$2 \" \" \$3 \" \" \$5 \" \" \$7}' | column -t"
----



[.console-output]
[source,bash]
----
NAME                      READY   STATUS    AGE   NODE
myboot-7cbfbd9b89-wpddg   1/1     Running   47s   devnation-m02
----


이제 포드가 실행 중인 노드를 찾아보겠습니다.

* *Terminal#1에서 실행*


[.console-input]
[source,bash,subs="+macros"]
----
NODE=$(kubectl get pod -o jsonpath='{.items[0].spec.nodeName}')
echo ${NODE}
----

NOTE:  `.items[0]`은 모든 포드를 요청하지만 목록에 요소가 하나만 포함된다는 것을 알고 있기 때문입니다.

[.console-output]
[source,bash]
----
"ip-10-0-146-109.eu-central-1.compute.internal"
----



* *Terminal#1에서 수행*

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl taint node ${NODE} color=blue:NoExecute
----

이 작업을 수행하자마자 Terminal#2 watch에서 이 "일정 변경"이 발생하는 것을 볼 수 있어야 합니다.


[.console-output]
[source,bash,subs="+quotes"]
----
NAME                      READY   STATUS              AGE   NODE
myboot-7cbfbd9b89-5t24z   0/1     #ContainerCreating#   16s   devnation
myboot-7cbfbd9b89-wpddg   1/1     #Terminating#         65m   devnation-m02
----


[NOTE]
====
사용 가능한 노드가 더 있으면 포드가 종료되고 다른 노드에 배포됩니다. 그렇지 않은 경우 포드는 '보류 중' 상태로 유지됩니다.
====


=== Clean Up

* *Terminal#1에서 작업*

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc delete deployment myboot
----


NoExecute 오염을 제거합니다.


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl taint node ${NODE} color=blue:NoExecute-
----




== Affinity & Anti-Affinity

Node/Pod Affinity 및 Anti-affinity를 사용하여 Pod가 예약되는 위치를 변경하는 또 다른 방법이 있습니다. + 
Pod가 실행될 수 있는 위치를 금지할 뿐만 아니라 Pod가 실행되어야 하는 위치를 선호하는 규칙을 만들 수 있습니다.

포드와 노드 간의 유사성을 생성하는 것 외에도 포드 간에 유사성을 생성할 수도 있습니다.  + 
Pod 그룹이 항상 동일한 노드에 함께 배포되어야 한다고 결정할 수 있습니다. Pod 간의 중요한 네트워크 통신과 같은 이유 때문에 외부 네트워크 호출이나 공유 저장 장치를 피하려고 합니다.


=== Node Affinity

노드 선호도를 사용하여 새 포드를 배포해 보겠습니다. 아래 내용을 살펴보세요.

[source, yaml]
----
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution: #<.>
        nodeSelectorTerms:
        - matchExpressions:
          - key: color
            operator: In
            values:
            - blue #<.>
      containers:
      - name: myboot
        image: quay.io/rhdevelopers/myboot:v1
----
<.> 이 핵심은 스케줄링 중에 다음 사항을 사용해야 하지만 Pod가 실행된 후에는 고려하지 않는다는 점을 강조합니다.
<.> `matchExpressions`는 이 포드가 `blue` 값 세트에 `color`가 있는 모든 노드에 대해 선호도가 있음을 나타냅니다.

이제 이를 배포해 보겠습니다.


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
cat <<EOF | oc create -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: myboot
  name: myboot
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myboot
  template:
    metadata:
      labels:
        app: myboot
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: color
                operator: In
                values:
                - blue
      containers:
      - name: myboot
        image: quay.io/rhdevelopers/myboot:v1
        ports:
          - containerPort: 8080
EOF
----


그러면 감시 창에서 보류 상태의 포드를 볼 수 있습니다.

==Terminal#2에서 확인

[.console-output]
[source,bash,subs="+macros,+attributes,+quotes"]
----
NAME                      READY   STATUS    AGE   NODE
myboot-546d4d9b45-7vgfc   0/1     #Pending#   6s    <none>
----


선호도 표현식과 일치하는 노드에 *레이블*을 만들어 보겠습니다.




노드 목록을 가져옵니다.

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get nodes
----

[.console-output]
[source,bash,subs="+attributes,+quotes"]
----
NAME                                            STATUS   ROLES    AGE   VERSION
ip-10-0-136-107.eu-central-1.compute.internal   Ready    master   26h   v1.16.2
ip-10-0-140-186.eu-central-1.compute.internal   Ready    worker   26h   v1.16.2
ip-10-0-141-128.eu-central-1.compute.internal   Ready    worker   25h   v1.16.2
ip-10-0-146-109.eu-central-1.compute.internal   Ready    worker   25h   v1.16.2
ip-10-0-150-226.eu-central-1.compute.internal   Ready    worker   26h   v1.16.2
ip-10-0-155-122.eu-central-1.compute.internal   Ready    master   26h   v1.16.2
ip-10-0-162-206.eu-central-1.compute.internal   Ready    worker   26h   v1.16.2
ip-10-0-168-102.eu-central-1.compute.internal   Ready    master   26h   v1.16.2
----

그런 다음 목록에서 레이블을 지정할 노드를 선택합니다

[.console-input]
[source,bash,subs="+macros,+attributes,+quotes"]
----
oc label nodes ip-10-0-150-226.eu-central-1.compute.internal  color=blue
----
IMPORTANT: nodename은 실제 조회 된 목록에서 가져와야 합니다. +
`color=blue` 이는 포드의 어피니티와 일치합니다.

[.console-output]
[source,bash,subs="+attributes"]
----
node/ip-10-0-150-226.eu-central-1.compute.internal labeled
----


그런 다음 Terminal#2 창에서 출력이 다음과 같이 변경되어야 합니다.


[.console-output]
[source,bash,subs="+macros,+attributes,+quotes"]
----
NAME                      READY   STATUS              AGE   NODE
myboot-546d4d9b45-7vgfc   0/1     #ContainerCreating#   15m   devnation-m02
----



포드가 실행 중인 노드에서 라벨을 삭제해 보겠습니다.


먼저 포드가 실행 중인 노드를 찾습니다.

[.console-input]
[source,bash,subs="+macros"]
----
NODE=$(kubectl get pod -o jsonpath='{.items[0].spec.nodeName}')
echo ${NODE}
----

그런 다음 색상 라벨을 제거하세요.

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc label nodes ${NODE} color-
----


그리고 watch 출력이 *변경되지 않고* 실행 중인 경우 포드가 계속 실행된다는 점을 확인하세요.

* *Terminal#2*

[.console-output]
[source,bash]
----
NAME                      READY   STATUS    AGE   NODE
myboot-546d4d9b45-7vgfc   1/1     Running   22m   devnation-m02
----


Pod의 배포 사양에서 'requiredDuringSchedulingIgnoredDuringExecution'을 사용했기 때문에 이전 섹션의 taint처럼 작동하는 친화력을 얻었습니다. 즉, 규칙은 예약 단계에서 설정되지만 그 이후에는 무시됩니다(예: 일단 실행되면  ).  따라서 우리의 경우에는 Pod가 제거되지 않습니다. 다음은 _하드_ 규칙의 예입니다.

.Hard Rule
****
Kubernetes 스케줄러가 필수 라벨이 있는 노드를 찾지 못하면 Pod는 _Pending_ 상태로 알려줍니다.
****

_soft_ 규칙을 만드는 방법도 있습니다:

.Soft Rule
****
Kubernetes 스케줄러는 규칙과 일치하려고 시도하지만 가능한 경우.  하지만 그렇게 할 수 없는 경우 포드는 모든 노드에 예약됩니다. 
****

아래 예를 고려하십시오.

[.console-output]
[source,yaml,subs="+macros,+attributes,+quotes"]
----
spec:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution: #<.>
      - weight: 1
        preference:
          matchExpressions:
          - key: color
            operator: In
            values:
            - blue
----
<.> _preferred_와 _required_라는 단어의 사용을 볼 수 있습니다.


==== Clean Up

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc delete deployment myboot
----



=== Pod Affinity/Anti-Affinity



Pod Affinity를 사용하여 새 Pod를 배포해 보겠습니다.  `{quick-open-file}`의 관련 부분을 참조하세요. 


[source, yaml]
.{quick-open-file}
----
spec:
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - topologyKey: kubernetes.io/hostname # <1>
        labelSelector: 
          matchExpressions:
          - key: app
            operator: In
            values:
            - myboot # <2>
  containers:
----

<1> 노드 레이블 키입니다.  두 노드가 이 키로 레이블이 지정되고 동일한 값을 갖는 경우 스케줄러는 두 노드를 동일한 토폴로지에 있는 것으로 처리합니다.  이 경우 `hostname`은 노드마다 다른 레이블입니다.
<2> 선호도는 'app=myboot' 라벨이 지정된 Pod와 관련됩니다.

* *Terminal#1에서 수행*

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
cat <<EOF | oc create -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: myboot2
  name: myboot2
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myboot2
  template:
    metadata:
      labels:
        app: myboot2
    spec:
      affinity:
        podAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - topologyKey: kubernetes.io/hostname
            labelSelector: 
              matchExpressions:
              - key: app
                operator: In
                values:
                - myboot
      containers:
      - name: myboot
        image: quay.io/rhdevelopers/myboot:v1
        ports:
          - containerPort: 8080
EOF
----

[.console-output]
[source,bash]
----
NAME                      READY  STATUS   AGE    NODE
myboot2-7c5f46cbc9-hwm2v  0/1    Pending  5h38m  <none>
----


선호도 규칙과 일치하는 포드를 찾을 수 없어 'myboot2' 포드가 보류 중입니다. 이 문제를 해결하려면 'app=myboot' 라벨이 지정된 'myboot' 애플리케이션을 배포해 보겠습니다.

* *Terminal#1에서 수행*

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
cat <<EOF | oc create -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: myboot
  name: myboot
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myboot
  template:
    metadata:
      labels:
        app: myboot
    spec:
      containers:
      - name: myboot
        image: quay.io/rhdevelopers/myboot:v1
        ports:
          - containerPort: 8080
EOF
----


그러면 둘 다 시작되고 _동일한 노드_에서 실행되는 것을 볼 수 있습니다.

* *Terminal#2에서 확인*

[.console-output]
[source,bash,subs="+quotes"]
----
NAME                      READY  STATUS             AGE    NODE
myboot-7cbfbd9b89-267k6   0/1    ContainerCreating  5s     #devnation-m02#
myboot2-7c5f46cbc9-hwm2v  0/1    ContainerCreating  5h45m  #devnation-m02#
----


[TIP]
====
방금 본 것은 _하드_ 규칙입니다. Pod Affinity에서도 "소프트" 규칙을 사용할 수 있습니다.

[.console-output]
[source, yaml, subs="+quotes"]
----
spec:
  affinity:
    podAntiAffinity:
      #preferredDuringSchedulingIgnoredDuringExecution:#
      - weight: 1
        podAffinityTerm:
          topologyKey: kubernetes.io/hostname 
          labelSelector:
            matchExpressions:  
            - key: app
              operator: In
              values:
              - myboot   
----
====

*Anti-affinity*는 두 개의 포드가 동일한 노드에서 함께 실행되지 않도록 하는 데 사용됩니다.


다른 포드를 추가해 보겠습니다.  `{quick-open-file}`의 다음 부분에 집중하세요


[.console-output]
[source, yaml]
.{quick-open-file}
----
spec:
  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - topologyKey: kubernetes.io/hostname
        labelSelector: 
          matchExpressions:
          - key: app
            operator: In
            values:
            - myboot
----

이는 기본적으로 `app=myboot` 라벨이 있는 포드가 있는 개별 노드(`topologyKey: kubernetes.io/hostname`)에서 이 포드를 예약해서는 안 된다는 것을 의미합니다. 
위의 반선호도 규칙을 사용하여 myboot3을 배포합니다.


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
cat <<EOF | oc create -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: myboot3
  name: myboot3
spec:
  replicas: 1
  selector:
    matchLabels:
      app: myboot3
  template:
    metadata:
      labels:
        app: myboot3
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - topologyKey: kubernetes.io/hostname
            labelSelector: 
              matchExpressions:
              - key: app
                operator: In
                values:
                - myboot
      containers:
      - name: myboot
        image: quay.io/rhdevelopers/myboot:v1
        ports:
          - containerPort: 8080
EOF
----


그런 다음 Watch 창에서 무슨 일이 일어나는지 확인하세요.

=
[.console-output]
[source,bash,subs="+macros,+attributes,+quotes"]
----
NAME                      READY  STATUS             AGE    NODE
myboot-7cbfbd9b89-267k6   1/1    Running            10m    devnation-m02
myboot2-7c5f46cbc9-hwm2v  1/1    Running            5h56m  devnation-m02
myboot3-6f95c866f6-7kvdw  0/1    ContainerCreating  6s     #devnation# 
----


하이라이트에서 볼 수 있듯이 'myboot3' 포드는 'myboot' 포드와 다른 노드에 배포됩니다.

==== Clean Up


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc delete deployment myboot
oc delete deployment myboot2
oc delete deployment myboot3
----


