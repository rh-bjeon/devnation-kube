= oc / kubectl : 쿠버네티스 클라이언트


== Kubernetes 및 OpenShift 명령줄 인터페이스
웹 콘솔에서 또는 kubectl 이나 oc CLI(명령줄 인터페이스)를 사용하여 OpenShift 클러스터를 관리할 수 있습니다. kubectl 명령은 Kubernetes에 기본 제공되며 Kubernetes API에 대한 Thin Wrapper입니다. OpenShift oc 명령은 kubectl 명령의 상위 집합이며 OpenShift 관련 기능에 대한 명령을 추가합니다. 

oc 명령을 사용하면 터미널에서 애플리케이션을 생성하고 Red Hat OpenShift Container Platform(RHOCP) 프로젝트를 관리할 수 있습니다. OpenShift CLI는 다음과 같은 상황에 적합합니다.

* 프로젝트 소스 코드를 사용하여 직접 작업

* OpenShift Container Platform 작업 스크립팅

* 대역폭으로 제한된 프로젝트 관리

* 웹 콘솔을 사용할 수 없는 경우

* routes 및 deployment configs와 같은 OpenShift 리소스 작업



* *kubectl*

kubernetes에서 기본적으로 제공 및 사용하는 CLI(CommandLine Interface)입니다. 
Kubernetes API와 상호작용하여 클러스터를 관리하는 데 사용됩니다.
표준 Kubernetes 명령어를 지원하며, 모든 kubernetes기반의 클러스터에서 동작합니다.

* *oc*

OpenShift에서 제공하는 CLI(CommandLine Interface)입니다. 
Kubernetes 기능위에 추가적인 기능(예: 추가 클러스터 관리명령, OpenShift 고유 리소스 관리 등)을 제공합니다.
kubectl 명령어를 기본적으로 포함합니다.


NOTE: 여기서부터 실습에서 사용되는 모든 명령어는 `Lab접속방법`에서 안내되었던 CLI 터미널 창에서 수행됩니다. 

== CLI 터미널 접속

OpenShift 웹콘솔의 오른쪽 상단의 웹터미널 아이콘을 클릭하여 CLI 터미널 창을 엽니다.
그 다음 '시작'버튼을 눌러 터미널을 활성화 합니다.

image::2-1.png[2-1]

image::2-3.png[2-3]

[[talk]]
== 클러스터에 로그인하고, 설정을 확인

NOTE: 일반적으로 클러스터에서 oc(kubectl) 명령어를 사용하기 위해서는 `oc login` 명령어를 통해 클러스터에 로그인해야 합니다. +
이 실습에서는 OpenShift의 웹콘솔에서 제공하는 웹터미널을 사용하기 때문에(이미 웹콘솔 로그인이 되어 있기 때문에) 로그인 단계가 필요없습니다.

[#kubectl-view-config]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
kubectl config view
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
apiVersion: v1
clusters:
- cluster:
    certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    server: https://172.30.0.1:443
  name: https://172.30.0.1:443
contexts:
- context:
    cluster: https://172.30.0.1:443
    namespace: openshift-terminal
    user: admin
  name: admin-context
current-context: admin-context
kind: Config
preferences: {}
users:
- name: admin
  user:
    token: REDACTED
----
NOTE: 현재 kubectl 설정 파일의 내용을 출력합니다. 여기에는 클러스터, 사용자 인증 정보, 컨텍스트 등의 정보가 포함됩니다.


[#kubectl-view-config]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc config view
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
apiVersion: v1
clusters:
- cluster:
    certificate-authority: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    server: https://172.30.0.1:443
  name: https://172.30.0.1:443
contexts:
- context:
    cluster: https://172.30.0.1:443
    namespace: openshift-terminal
    user: admin
  name: admin-context
current-context: admin-context
kind: Config
preferences: {}
users:
- name: admin
  user:
    token: REDACTED
----

NOTE: 기본적으로 `oc` 명령어는 `kubectl` 명령을 포함하고 있기 때문에 두 명령어의 결과는 동일합니다.또한 `oc` 명령어는 `kubectl` 에는 포함되어 있지않은 추가 리소스에 대한 명령어도 포함하고 있습니다.

IMPORTANT: 앞으로의 실습에는 `oc` 명령어를 사용합니다.




== 노드, 시스템, 시스템 구성의 개요
Kubernetes에서 노드 는 포드를 실행할 수 있는 클러스터의 단일 시스템입니다. 이러한 시스템은 클러스터의 멤버인 베어 메탈, 가상 또는 클라우드 컴퓨터 중 하나입니다. 노드는 클러스터 내에서 통신하고 컨트롤 플레인 운영 요청을 수신하는 데 필요한 서비스를 실행합니다. 포드를 배포할 때 사용 가능한 노드는 요청을 충족하는 작업을 수행합니다.

노드 및 시스템 이라는 용어는 흔히 서로 바꿔 사용할 수 있지만 Red Hat OpenShift Container Platform(RHOCP)에서는 시스템 이라는 용어를 더 구체적으로 사용합니다. OpenShift에서 시스템 은 클러스터 노드를 설명하는 리소스입니다. 

* *Master Node* : Master 노드는 클러스터의 관리 및 제어 역할을 담당합니다. 모든 클러스터 상태와 관리 작업은 Master 노드에서 이루어집니다. 다음과 같은 주요 역할을 수행합니다.
 - API Server (Kube-apiserver) : 클러스터와 상호작용하는 진입점(API 엔드포인트)을 제공하고, 사용자, 개발자, 클라이언트와 통신하여 요청을 처리합니다.
 -  Scheduler (Kube-scheduler) : 워크로드(Pod)를 적절한 Worker 노드에 배치합니다. 리소스 상태와 요구 사항을 기반으로 최적의 노드를 선택합니다.
 -  Controller Manager (Kube-controller-manager) : 클러스터 상태를 원하는 상태로 유지합니다.
 -  Etcd : 클러스터의 모든 상태 정보를 저장하는 분산형 키-값 저장소.

* *Worker Node* : Worker 노드는 실제로 워크로드(Pod, 컨테이너)를 실행하는 노드입니다. 주요 구성요소는 다음과 같습니다.
 - Kubelet : 노드 내에서 Pod를 관리하는 에이전트.
 - Kube-proxy : 네트워크 통신을 관리하는 네트워크 프록시.
 - Container Runtime : 컨테이너 실행 환경을 제공

* *Infra Node* : Infra 노드는 클러스터 서비스(내부 서비스)를 실행하는 전용 노드로, 사용자 워크로드와 분리된 환경에서 동작하도록 설계되었습니다.
 - 클러스터 서비스 호스팅 : 클러스터 내 네트워크, 모니터링, 로깅, 레지스트리 등 OpenShift 내부 서비스 실행.
 - 로드 밸런싱 및 네트워크 게이트웨이 : 외부 트래픽을 클러스터 내부로 라우팅.
 - 서비스 안정성 향상 : 사용자 워크로드와 클러스터 서비스를 분리하여 상호 간의 간섭을 최소화



[[view-nodes]]
== 클러스터를 구성하는 Nodes 확인

[#kubectl-get-nodes]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get nodes
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                                        STATUS   ROLES                  AGE    VERSION
ip-10-0-27-23.us-east-2.compute.internal    Ready    worker                 2d1h   v1.28.14+502c5ce
ip-10-0-29-131.us-east-2.compute.internal   Ready    worker                 2d1h   v1.28.14+502c5ce
ip-10-0-35-173.us-east-2.compute.internal   Ready    infra,worker           2d     v1.28.14+502c5ce
ip-10-0-38-201.us-east-2.compute.internal   Ready    control-plane,master   2d1h   v1.28.14+502c5ce
ip-10-0-38-226.us-east-2.compute.internal   Ready    control-plane,master   2d1h   v1.28.14+502c5ce
ip-10-0-56-21.us-east-2.compute.internal    Ready    control-plane,master   2d1h   v1.28.14+502c5ce
ip-10-0-63-222.us-east-2.compute.internal   Ready    worker                 2d1h   v1.28.14+502c5ce
----

[#kubectl-get-nodes]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get nodes --show-labels
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                                        STATUS   ROLES                  AGE    VERSION            LABELS
ip-10-0-27-23.us-east-2.compute.internal    Ready    worker                 2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m6a.8xlarge,beta.kubernetes.io/os=linux,cluster.ocs.openshift.io/openshift-storage=,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-27-23.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/worker=,node.kubernetes.io/instance-type=m6a.8xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a,topology.rook.io/rack=rack0
ip-10-0-29-131.us-east-2.compute.internal   Ready    worker                 2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m6a.8xlarge,beta.kubernetes.io/os=linux,cluster.ocs.openshift.io/openshift-storage=,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-29-131.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/worker=,node.kubernetes.io/instance-type=m6a.8xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a,topology.rook.io/rack=rack1
ip-10-0-35-173.us-east-2.compute.internal   Ready    infra,worker           2d     v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5a.2xlarge,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-35-173.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/infra=,node-role.kubernetes.io/worker=,node.kubernetes.io/instance-type=m5a.2xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a
ip-10-0-38-201.us-east-2.compute.internal   Ready    control-plane,master   2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5a.2xlarge,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-38-201.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=,node.kubernetes.io/instance-type=m5a.2xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a
ip-10-0-38-226.us-east-2.compute.internal   Ready    control-plane,master   2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5a.2xlarge,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-38-226.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=,node.kubernetes.io/instance-type=m5a.2xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a
ip-10-0-56-21.us-east-2.compute.internal    Ready    control-plane,master   2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m5a.2xlarge,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-56-21.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/control-plane=,node-role.kubernetes.io/master=,node.kubernetes.io/instance-type=m5a.2xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a
ip-10-0-63-222.us-east-2.compute.internal   Ready    worker                 2d1h   v1.28.14+502c5ce   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m6a.8xlarge,beta.kubernetes.io/os=linux,cluster.ocs.openshift.io/openshift-storage=,failure-domain.beta.kubernetes.io/region=us-east-2,failure-domain.beta.kubernetes.io/zone=us-east-2a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-10-0-63-222.us-east-2.compute.internal,kubernetes.io/os=linux,node-role.kubernetes.io/worker=,node.kubernetes.io/instance-type=m6a.8xlarge,node.openshift.io/os_id=rhcos,topology.ebs.csi.aws.com/zone=us-east-2a,topology.kubernetes.io/region=us-east-2,topology.kubernetes.io/zone=us-east-2a,topology.rook.io/rack=rack2[[view-pods]]
----

NOTE: `oc get nodes` : 클러스터 내의 모든 노드를 목록으로 출력합니다. +
`oc get nodes --show-labels` : 노드의 정보를 출력하면서 각 노드에 적용된 라벨도 표시합니다.


== Red Hat OpenShift 주요 개념
OpenShift 기능을 탐색할 때 OpenShift, Kubernetes, 컨테이너 기술에 대한 몇 가지 입문 용어를 알고 있으면 유용합니다. +
다음 목록에는 OpenShift를 탐색하는 데 도움이 되는 몇 가지 기본 개념이 포함되어 있습니다.

* *Pod* : Kubernetes에서 관리하는 컨테이너화된 애플리케이션의 가장 작은 단위입니다. 포드는 하나 이상의 컨테이너로 구성됩니다.

* *Deployment* : 실행 중인 애플리케이션을 세부적으로 관리할 수 있는 운영 단위입니다.

* *Project* : 애플리케이션에 멀티 테넌시 범위를 제공하는 추가 주석이 있는 Kubernetes 네임스페이스입니다.

* *Routes* : 클러스터 외부 리소스에 애플리케이션 및 서비스를 노출하는 네트워킹 구성입니다.OpenShift 라우터에서 애플리케이션 및 마이크로서비스의 진입 지점으로 인식하는 DNS 호스트 이름을 나타냅니다.

* *Operators* : 클러스터 기능을 확장하며 패키지로 제공되는 Kubernetes 애플리케이션입니다.

* *Service* : 포드의 풀에 대한 액세스를 제공하는 단일 IP/포트 결합을 정의합니다. 기본적으로 서비스는 라운드 로빈 방식으로 클라이언트를 포드에 연결합니다.

* *ReplicaSet(rs)* : 지정된 수의 포드 복제본이 지정된 시간에 실행되고 있는지 확인합니다.

* *Persistent Volumes (pv)* : Kubernetes 포드에서 사용할 스토리지 영역을 정의합니다.

* *Persistent Volume Claims (pvc)* : 포드의 스토리지 요청을 나타냅니다. PVC는 일반적으로 스토리지를 컨테이너의 파일 시스템에 마운트하여 해당 컨테이너에서 프로비저닝된 스토리지를 사용할 수 있도록 PV를 포드에 연결합니다.

* *ConfigMaps(cm) 및 Secrets* : 다른 리소스에서 사용할 수 있는 일련의 키와 값이 포함되어 있습니다. ConfigMaps 및 Secrets는 여러 리소스에서 사용하는 구성 값을 중앙 집중화합니다. Secrets는 Secrets의 값이 항상 인코딩되고(암호화되지 않음) 액세스 권한이 소수의 권한 있는 사용자로 제한된다는 점에서 ConfigMaps와 다릅니다.

* *Deployment (deploy)* : 포드에 포함된 컨테이너 집합 및 사용할 배포 전략을 나타냅니다. deployment 오브젝트에는 기본 이미지, 태그, 스토리지 정의, 컨테이너가 시작될 때 실행할 명령 등 각 포드 복제본의 모든 컨테이너에 적용할 구성이 포함됩니다. Kubernetes 복제본은 OpenShift에서 독립 실행형으로 생성할 수 있지만 일반적으로 배포 컨트롤러와 같은 고급 수준의 리소스에서 생성합니다.

*Red Hat OpenShift Container Platform(RHOCP)에서는 Kubernetes에 다음과 같은 주요 리소스 유형을 추가합니다.*

* *BuildConfig(bc)* : OpenShift 프로젝트에서 실행할 프로세스를 정의합니다. OpenShift S2I(Source-to-Image) 기능에서는 BuildConfig를 사용하여 Git 리포지토리에 저장된 애플리케이션 소스 코드에서 컨테이너 이미지를 빌드합니다. bc 는 dc 와 공동으로 작업하여 확장 가능한 지속적 통합 및 지속적 제공 워크플로를 제공합니다.

* *DeploymentConfig(dc)* : OpenShift 4.5에서는 포드의 DeploymentConfig 기본 구성을 교체하기 위해 Deployment 리소스 개념을 도입했습니다. 두 개념 모두 포드에 포함된 컨테이너 집합 및 사용할 배포 전략을 나타냅니다.

 - Deployment 오브젝트는 DeploymentConfig 오브젝트의 개선된 버전으로 제공합니다. 다음은 두 오브젝트 간 몇 가지 대체 기능입니다.

 - Deployment 오브젝트는 더 이상 자동 롤백 또는 라이프사이클 후크를 지원하지 않습니다.

 - Deployment 오브젝트에서 사용하는 포드 템플릿을 변경할 때마다 새 롤아웃이 자동으로 트리거됩니다.

 - Deployment 오브젝트의 배포 프로세스는 배포자 프로세스에 영향을 주지 않고 언제든 일시 중지할 수 있습니다.

 - Deployment 오브젝트는 사용자가 원하는 만큼의 활성 복제본 집합이 있을 수 있으며 이전 복제본을 축소할 수 있습니다. 반대로 DeploymentConfig 오브젝트에는 동시에 두 개의 복제본 집합만 활성화될 수 있습니다.




== 클러스터에 배포되어 있는 `Pods` 를 확인


[#kubectl-get-pods]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get pods -n codeserver-%userid%
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                          READY   STATUS    RESTARTS   AGE
codeserver-85f5475758-pxhvp   1/1     Running   0          3d7h
----


[#kubectl-get-pods]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get pods -n codeserver-%userid% --show-labels
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                          READY   STATUS    RESTARTS   AGE    LABELS
codeserver-85f5475758-pxhvp   1/1     Running   0          3d7h   app.kubernetes.io/instance=codeserver-user1,app.kubernetes.io/name=codeserver,pod-template-hash=85f5475758
----

[#kubectl-get-pods]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get pods -n codeserver-%userid% -o wide
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                          READY   STATUS    RESTARTS   AGE    IP             NODE                                        NOMINATED NODE   READINESS GATES
codeserver-85f5475758-pxhvp   1/1     Running   0          3d7h   10.128.2.116   ip-10-0-106-38.us-east-2.compute.internal   <none>           <none>
----


NOTE: `oc get pods -n codeserver-%userid%` : 해당 네임스페이스에서 실행 중인 pod의 정보를 출력합니다. +
`oc get pods -n codeserver-%userid% --show-labels` : 해당 네임스페이스에서 파드 정보를 출력하며, 파드에 적용된 라벨도 함께 표시합니다. +
`oc get pods -n codeserver-%userid% -o wide` : 파드의 정보를 좀 더 상세하게 출력합니다. 예를 들어, 노드의 이름과 IP 주소 등 추가 정보를 보여줍니다.



[[deploy-app]]
== 배포를 진행해 보세요.

네임스페이스를 생성하고  deployment를 배포합니다:

[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc new-project mystuff-%userid%
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
namespace/mystuff-%userid% created
----

NOTE: `oc new-project mystuff-%userid%` : mystuff-%userid%라는 새 프로젝트(네임스페이스)를 생성합니다.

[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc project mystuff-%userid%
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Now using project "mystuff-%userid%" on server "https://172.30.0.1:443".
----

NOTE: `oc project mystuff-%userid%` : 현재 활성화된 컨텍스트의 기본 네임스페이스를 mystuff-%userid%로 변경합니다.

[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc create deployment myapp --image=quay.io/rhdevelopers/quarkus-demo:v1
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
deployment.apps/myapp created
----


NOTE: `oc create deployment myapp --image=quay.io/rhdevelopers/quarkus-demo:v1` : quay.io/rhdevelopers/quarkus-demo:v1 이미지를 기반으로 하는 myapp이라는 이름의 `deployment` 를 생성합니다.



[[monitor-events]]
== 배포를 진행하는 동안 이벤트를 모니터링

[#kubectl-get-events]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
watch oc get events --sort-by=.metadata.creationTimestamp
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
LAST SEEN   TYPE     REASON              OBJECT                        MESSAGE
<unknown>   Normal   Scheduled           pod/myapp-5dcbf46dfc-ghrk4    Successfully assigned mystuff/myapp-5dcbf46dfc-ghrk4 to g
cp-5xldg-w-a-5ptpn.us-central1-a.c.ocp42project.internal
29s         Normal   SuccessfulCreate    replicaset/myapp-5dcbf46dfc   Created pod: myapp-5dcbf46dfc-ghrk4
29s         Normal   ScalingReplicaSet   deployment/myapp              Scaled up replica set myapp-5dcbf46dfc to 1
21s         Normal   Pulling             pod/myapp-5dcbf46dfc-ghrk4    Pulling image "quay.io/burrsutter/quarkus-demo:1.0.0"
15s         Normal   Pulled              pod/myapp-5dcbf46dfc-ghrk4    Successfully pulled image "quay.io/burrsutter/quarkus-dem
o:1.0.0"
15s         Normal   Created             pod/myapp-5dcbf46dfc-ghrk4    Created container quarkus-demo
15s         Normal   Started             pod/myapp-5dcbf46dfc-ghrk4    Started container quarkus-demo
----

NOTE: `watch oc get events` : 클러스터 이벤트를 생성 시간순으로 실시간 모니터링합니다. watch 명령은 주기적으로 결과를 갱신합니다.

NOTE: `watch` 명령어를 종료하려면, [ctrl+c]를 입력합니다.

[[created-objects]]
== 생성된 Objects를 확인하세요.

=== Deployments
[#kubectl-get-deployments]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get deployments
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME    READY   UP-TO-DATE   AVAILABLE   AGE
myapp   1/1     1            1           95s
----

NOTE: `oc get deployments` : 배포된 `deployments` 목록을 확인합니다.



=== Replicasets
[#kubectl-get-replicasets]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get replicasets
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME               DESIRED   CURRENT   READY   AGE
myapp-5dcbf46dfc   1         1         1       2m1s
----

NOTE: `oc get replicasets` : 배포된 `replicasets` 목록을 확인합니다.



=== Pods

[#kubectl-get-podsx]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc get pods --show-labels
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                     READY   STATUS    RESTARTS   AGE     LABELS
myapp-5dcbf46dfc-ghrk4   1/1     Running   0          2m18s   app=myapp,pod-template-hash=5dcbf46dfc
----

NOTE: `oc get pods --show-labels` : 배포된 `pod` 목록을 label값을 포함하여 확인합니다.


=== Logs
[#kubectl-logs]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc logs -l app=myapp
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
2020-03-22 14:41:30,497 INFO  [io.quarkus] (main) Quarkus 0.22.0 started in 0.021s. Listening on: http://0.0.0.0:8080
2020-03-22 14:41:30,497 INFO  [io.quarkus] (main) Installed features: [cdi, resteasy]
----

NOTE: `oc logs -l app=myapp` : `app=myapp` label이 포함된 pod의 로그를 출력합니다.


== Service 노출

[#kubectl-expose]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc expose deployment myapp --port=8080 --type=LoadBalancer
----

수행하는 동안 서비스를 조회하세요.

[#{section-k8s}-kubectl-watch-services]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
watch oc get services
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME    TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE
myapp   LoadBalancer   172.30.103.41   <pending>     8080:31974/TCP   4s
----

외부 IP가 할당될 때까지 기다리세요.



[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME    TYPE           CLUSTER-IP      EXTERNAL-IP     PORT(S)          AGE
myapp   LoadBalancer   172.30.103.41   34.71.122.153   8080:31974/TCP   44s
----

NOTE: `watch` 명령어를 종료하려면, [ctrl+c]를 입력합니다.


== Talk to the App

OpenShift와 같은 호스팅된 Kubernetes 클러스터를 사용하는 경우 `8080` 포트와 함께 `curl` 및 EXTERNAL-IP 주소를 사용하거나 `kubectl(oc)` 을 사용하여 가져옵니다.:

IMPORTANT: AWS에 있는 경우 `ip` 대신 `hostname` 을 가져와야 합니다. 아래 명령어는 hostname을 가져옵니다.


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
IP=$(kubectl get service myapp -o jsonpath="{.status.loadBalancer.ingress[0].hostname}")
----


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
PORT=$(kubectl get service myapp -o jsonpath="{.spec.ports[*].port}")
----


Curl the Service:

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
curl $IP:$PORT
----


[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Supersonic Subatomic Java with Quarkus myapp-b484fbf6-25kcz:1
----

IMPORTANT: curl 명령어를 수행하여 app이 hosting하고 있는 문구를 확인합니다.


== Application 확장

명령줄 터미널에서 +버튼을 눌러 3개의 터미널 창을 엽니다.

image::2-4.png[2-4]



* *Terminal 1번*


[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc project mystuff-%userid%
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Now using project "mystuff-%userid%" on server "https://172.30.0.1:443".
----

[#watch-pods]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
watch oc get pods
----

NOTE: 터미널 1번은 지속적으로 pod list를 출력하며, replicaset이 변경됨에 따라 pod수가 1개에서 3개로 늘어나는 것을 확인할 수 있습니다.

* *Terminal 2번*


[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc project mystuff-%userid%
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Now using project "mystuff-%userid%" on server "https://172.30.0.1:443".
----

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
IP=$(kubectl get service myapp -o jsonpath="{.status.loadBalancer.ingress[0].hostname}")
----


[.console-input]
[source,bash,subs="+macros,+attributes"]
----
PORT=$(kubectl get service myapp -o jsonpath="{.spec.ports[*].port}")
----


Curl the Service:

[.console-input]
[source,bash,subs="+macros,+attributes"]
----
curl $IP:$PORT
----


Poll the endpoint:

[#poll-endpoint]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
while true
do curl $IP:$PORT
sleep 0.8
done
----

polling 결과는 다음과 같습니다.:

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:289
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:290
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:291
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:292
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-ghrk4:293
----

NOTE: 터미널 2번은 지속적으로 3개의 pod로의 curl poling을 시도합니다. application의 이미지를 변경하여 Rolling update가 진행됨에 따라 실시간으로 poling 결과값이 변하는 것을 관찰할 수 있습니다.


* *Terminal 3번*

[#kubectl-deploy-app]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc project mystuff-%userid%
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Now using project "mystuff-%userid%" on server "https://172.30.0.1:443".
----


replicas 변경:

[#change-replicas]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc scale deployment myapp --replicas=3
----



[.console-output]
[source,bash,subs="+macros,+attributes"]
----
NAME                     READY   STATUS              RESTARTS   AGE
myapp-5dcbf46dfc-6sn2s   0/1     ContainerCreating   0          4s
myapp-5dcbf46dfc-ghrk4   1/1     Running             0          5m32s
myapp-5dcbf46dfc-z6hqw   0/1     ContainerCreating   0          4s
----

NOTE: 해당 결과는 터미널 1번에서 확인합니다.  터미널 1번은 지속적으로 pod list를 출력하며, replicaset이 변경됨에 따라 pod수가 1개에서 3개로 늘어나는 것을 확인할 수 있습니다.


이미지를 변경하여 롤링 업데이트 시작:

[#set-image-myboot-v1]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc set image deployment/myapp quarkus-demo=quay.io/rhdevelopers/myboot:v1
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-6sn2s:188
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-z6hqw:169
Aloha from Spring Boot! 0 on myapp-58b97dbd95-vxd87
Aloha from Spring Boot! 1 on myapp-58b97dbd95-vxd87
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-6sn2s:189
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-z6hqw:170
Aloha from Spring Boot! 2 on myapp-58b97dbd95-vxd87
----

NOTE: 해당 결과는 터미널 2번에서 확인합니다. 터미널 2번은 지속적으로 3개의 pod로의 curl poling을 시도합니다. application의 이미지를 변경하여 Rolling update가 진행됨에 따라 실시간으로 poling 결과값이 변하는 것을 관찰할 수 있습니다.



[#set-image-myboot-v2]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc set image deployment/myapp quarkus-demo=quay.io/rhdevelopers/myboot:v2
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Bonjour from Spring Boot! 2 on myapp-7d58855c6b-6c8gd
Bonjour from Spring Boot! 3 on myapp-7d58855c6b-6c8gd
Aloha from Spring Boot! 7 on myapp-58b97dbd95-mjlwx
Bonjour from Spring Boot! 4 on myapp-7d58855c6b-6c8gd
Aloha from Spring Boot! 8 on myapp-58b97dbd95-mjlwx
Bonjour from Spring Boot! 5 on myapp-7d58855c6b-6c8gd
----

NOTE: 해당 결과는 터미널 2번에서 확인합니다. 터미널 2번은 지속적으로 3개의 pod로의 curl poling을 시도합니다. application의 이미지를 변경하여 Rolling update가 진행됨에 따라 실시간으로 poling 결과값이 변하는 것을 관찰할 수 있습니다.


[#set-image-quarkus-demo]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc set image deployment/myapp quarkus-demo=quay.io/rhdevelopers/quarkus-demo:v1
----

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Bonjour from Spring Boot! 14 on myapp-7d58855c6b-dw67s
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:3
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:4
Bonjour from Spring Boot! 15 on myapp-7d58855c6b-dw67s
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:5
Bonjour from Spring Boot! 13 on myapp-7d58855c6b-72wp8
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7rkxj:1
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7rkxj:2
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7lf9t:1
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7rkxj:3
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7lf9t:2
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-7lf9t:3
Supersonic Subatomic Java with Quarkus myapp-5dcbf46dfc-tcfwp:6
----

NOTE: 해당 결과는 터미널 2번에서 확인합니다. 터미널 2번은 지속적으로 3개의 pod로의 curl poling을 시도합니다. application의 이미지를 변경하여 Rolling update가 진행됨에 따라 실시간으로 poling 결과값이 변하는 것을 관찰할 수 있습니다.

== Clean Up

[#delete-namespace]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc delete all --all -n mystuff-%userid%
----

NOTE: *mystuff-%userid%* namespace의 모든 리소스가 삭제됩니다.

[#delete-namespace]
[.console-input]
[source,bash,subs="+macros,+attributes"]
----
oc delete namespace mystuff-%userid%
----

NOTE: *mystuff-%userid%* namespace를 삭제합니다.
